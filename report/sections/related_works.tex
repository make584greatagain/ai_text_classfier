
% -----------------------------------------------------------------
% Related Works section (insert after Introduction)
% -----------------------------------------------------------------
\section{Related Works}   % -- Section title --

% -- Paragraph 1: Early rule-based & classic ML approaches --
Early attempts to distinguish AI\textendash generated text primarily relied on traditional natural language processing techniques, such as rule\textendash based systems and basic machine learning algorithms including Naïve Bayes and Support Vector Machines (SVM). These methods often utilized surface\textendash level linguistic features such as word frequency distributions, grammatical patterns, and stylistic markers. However, as AI‐generated text became increasingly sophisticated, these simpler models began to lose effectiveness.

% -- Paragraph 2: Rise of transformer-based deep learning --
Recent literature has shifted toward deep learning approaches, leveraging the power of neural network architectures to improve detection accuracy. Transformer‐based models, particularly BERT and GPT variants, have demonstrated significant success due to their ability to understand contextual and semantic information at deeper levels. Several studies highlight the effectiveness of fine‐tuning pre‐trained transformer models on specific datasets, achieving notable improvements in accuracy and generalization capabilities.

% -- Paragraph 3: Gradient boosting techniques --
Gradient boosting techniques, such as XGBoost, LightGBM, and CatBoost, have also shown promising results in text classification tasks, including the detection of AI‐generated content. These models excel in handling high‐dimensional, sparse data typical of textual datasets, and their capability to model complex feature interactions has made them highly competitive in recent benchmarking studies.

% -- Paragraph 4: Remaining challenges (domain shift, interpretability) --
Despite these advancements, challenges remain, particularly in generalizing detection capabilities to unseen and evolving text generation models. Previous studies indicate substantial performance degradation when models trained on earlier generation language models are tested against outputs from newer, more advanced AI systems. This highlights an ongoing need for developing detection techniques that incorporate adaptive learning, domain‐shift handling, and enhanced interpretability mechanisms.

% -- Paragraph 5: Our study's position --
Our study builds on these insights, systematically evaluating both classical and advanced detection methodologies, identifying their respective strengths and limitations, and proposing future research directions to effectively address the persistent challenges in AI‐generated text detection.
