
% -----------------------------------------------------------------
% Conclusion section (insert after Results)
% -----------------------------------------------------------------
\section{Conclusion}  % -- Section VI --

% -- Paragraph 1: Summary of evaluation --
This study systematically evaluated a spectrum of methodologies for
detecting AI‐generated text, revealing both strengths and critical
limitations. Baseline algorithms achieved only moderate success and
struggled with sophisticated GPT-level outputs. In contrast, advanced
models—particularly CatBoost—substantially outperformed baselines by
capturing complex textual features, yet still encountered notable
generalisation issues on independently sourced data.

% -- Paragraph 2: Asymmetry and bias --
Results also exposed substantial asymmetry: detectors showed higher
accuracy for AI‐generated passages than for human‐written ones, implying
potential training‐data bias and underscoring the need for balanced,
representative corpora.

% -- Paragraph 3: Future directions --
Future research should prioritise robustness to emerging generative
technologies, enhanced interpretability, and ensemble strategies that
combine complementary model strengths. Expanding training datasets with
diverse, up-to-date AI‐generated samples will be essential to mitigate
domain shift and improve real-world applicability.
